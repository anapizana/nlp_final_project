{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Neural network feed forward classifier with word embeddings for sentiment analysis \n",
    "\n",
    "# => structure:\n",
    "# 1. input --> hidden: linear(input_dim, hidden_dim)\n",
    "# 2. tanh action\n",
    "# 3. hidden --> output: linear(hidden_dim, 2)\n",
    "# 4. log softmax\n",
    "\n",
    "# => use pretrained glove word embeddings \n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import math \n",
    "import re \n",
    "import pickle\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "train_dataset = pd.read_csv(\"train_dataset.csv\")\n",
    "test_dataset = pd.read_csv(\"test_dataset.csv\")\n",
    "train_notes = train_dataset['note'].as_matrix()\n",
    "test_notes = test_dataset['note'].as_matrix()\n",
    "\n",
    "train_y = train_dataset['label'].as_matrix()\n",
    "test_y = test_dataset['label'].as_matrix()\n",
    "\n",
    "# converting train and test to clean format \n",
    "print \"Converting training to no numbers\"\n",
    "for i in range(len(train_notes)):\n",
    "    note = train_notes[i].lower()\n",
    "    string = re.sub(\"\\d+\", \"\", note)\n",
    "    train_notes[i] = \" \".join(re.findall(r'\\w+', string))\n",
    "\n",
    "print \"Converting testing to no numbers\"\n",
    "for i in range(len(test_notes)):\n",
    "    note = test_notes[i].lower()\n",
    "    string = re.sub(\"\\d+\", \"\", note)\n",
    "    test_notes[i] = \" \".join(re.findall(r'\\w+', string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ADAPTED FROM 6.864\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "batch_size = 173\n",
    "hidden_dim = 300\n",
    "weight_decay = 1e-5\n",
    "lr = 1e-3\n",
    "\n",
    "# extract text from word2vec\n",
    "f = gzip.open('word_vectors.txt.gz', 'r')\n",
    "wv = [ ]\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    wv.append(line.strip())\n",
    "\n",
    "embeddings = {}\n",
    "for line in wv: \n",
    "    parts = line.split()\n",
    "    word = parts[0]\n",
    "    vector = np.array([float(v) for v in parts[1:]])\n",
    "    embeddings[word] = vector\n",
    "\n",
    "    \n",
    "def extract_embeddings(data):\n",
    "    features = [ ]\n",
    "    for i in range(len(data)):\n",
    "        num_words = 0\n",
    "        current_feature = [ 0.0 for _ in range(300) ]\n",
    "        for word in data[i].split():\n",
    "            if word in word_to_vec:\n",
    "                current_feature += embeddings[word]/np.linalg.norm(embeddings[word])\n",
    "                num_words += 1\n",
    "\n",
    "        if num_words > 0:\n",
    "            current_feature /= num_words\n",
    "\n",
    "        features.append(current_feature)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### CODE ADAPTED FROM 6.864\n",
    "\n",
    "# feature extraction and define dataset\n",
    "train_x = extract_embeddings(train_notes)\n",
    "test_x = extract_embeddings(test_notes)\n",
    "\n",
    "train_y = train_y.astype(int)\n",
    "test_y = test_y.astype(int)\n",
    "\n",
    "print \"datatype\"\n",
    "print train_y.dtype\n",
    "print test_y.dtype \n",
    "\n",
    "train_x, dev_x, train_y, dev_y = train_test_split(train_x, train_y, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(train_x), torch.LongTensor(train_y))\n",
    "dev_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(dev_x), torch.LongTensor(dev_y))\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(test_x), torch.LongTensor(test_y))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "\n",
    "### CODE FROM 6.864\n",
    "class FFN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFN, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_dim, output_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.LogSoftmax()\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return x\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    actual = []\n",
    "    for data, label in loader:\n",
    "        data, label = Variable(data), Variable(label)\n",
    "        output = model(data)\n",
    "        output = output.data.cpu().numpy()\n",
    "        pred = np.concatenate((pred, np.argmax(output, axis=1)), axis=0)\n",
    "        actual = np.concatenate((actual, label.data.cpu().numpy()), axis=0)\n",
    "\n",
    "    return metrics.accuracy_score( y_pred=pred, y_true=actual)\n",
    "\n",
    "def train(model, loader, max_epoches, dev_loader, test_loader, verbose=False):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_dev = 0.0\n",
    "    corresponding_test = 0.0\n",
    "    for epoch in range(max_epoches):\n",
    "        model.train()\n",
    "        for data, label in train_loader:\n",
    "            data, label = Variable(data), Variable(label)\n",
    "            model.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        dev = evaluate(model, dev_loader)\n",
    "        test = evaluate(model, test_loader)\n",
    "        if dev > best_dev:\n",
    "            best_dev = dev\n",
    "            corresponding_test = test\n",
    "\n",
    "    print (best_dev, corresponding_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = FFN(100, hidden_dim, 2)\n",
    "train(model, train_loader, 50, dev_loader, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
